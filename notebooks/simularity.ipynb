{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import itertools # Для создания пар\n",
    "\n",
    "# Предположим, что у вас есть код ваших классов\n",
    "from src.model.siam import HierarchicalSignalNet\n",
    "from src.dataloader.dataloader import SignalDataset, create_dummy_data\n",
    "\n",
    "# --- 1. Загрузка обученной модели ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EMBEDDING_DIM = 64 # Должен совпадать с тем, что использовался при обучении\n",
    "model = HierarchicalSignalNet(embedding_dim=EMBEDDING_DIM)\n",
    "model.load_state_dict(torch.load(\"path/to/your/trained_model.pth\")) # Укажите путь к вашим весам\n",
    "model.to(DEVICE)\n",
    "model.eval() # !!! ОБЯЗАТЕЛЬНО переводим модель в режим оценки\n",
    "\n",
    "# --- 2. Создание валидационного набора данных ---\n",
    "# ВАЖНО: Используйте данные, которые не участвовали в обучении!\n",
    "# Например, можно сгенерировать новый набор или выделить часть изначальных данных.\n",
    "val_signals, val_element_ids, val_session_ids, val_keypoints = create_dummy_data(\n",
    "    num_elements=5, sessions_per_element=5, signals_per_session=5, start_el_id=100\n",
    ")\n",
    "val_dataset = SignalDataset(val_signals, val_element_ids, val_session_ids, val_keypoints)\n",
    "\n",
    "print(f\"Создан валидационный набор данных из {len(val_dataset)} сигналов.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf7a578",
   "metadata": {},
   "source": [
    "### Шаг 2: Вычисление Оптимального Порога\n",
    "Это самый важный шаг. Мы прогоним все возможные пары сигналов из нашего валидационного набора через модель, вычислим расстояния и найдем порог, который лучше всего разделяет пары \"из одного замера\" и пары \"из разных замеров\". Для этого идеально подходит ROC-кривая (Receiver Operating Characteristic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9982023",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m optimal_threshold\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Вычисляем наш порог\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m SESSION_THRESHOLD \u001b[38;5;241m=\u001b[39m find_optimal_threshold(\u001b[43mmodel\u001b[49m, val_dataset, DEVICE)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def find_optimal_threshold(model, dataset, device):\n",
    "    \"\"\"\n",
    "    Вычисляет оптимальный порог расстояния для разделения замеров,\n",
    "    используя ROC-кривую на валидационном наборе данных.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    session_ids = []\n",
    "\n",
    "    # Сначала получим эмбеддинги для всех сигналов в наборе\n",
    "    with torch.no_grad(): # Отключаем расчет градиентов\n",
    "        for i in range(len(dataset)):\n",
    "            sample = dataset[i]\n",
    "            signal_tensor = torch.tensor(sample['signal'], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "            # unsqueeze(0) добавляет batch и channel размерности\n",
    "            \n",
    "            emb, _ = model(signal_tensor)\n",
    "            embeddings.append(emb.cpu().numpy().flatten())\n",
    "            session_ids.append(sample['session_id'])\n",
    "\n",
    "    embeddings = np.array(embeddings)\n",
    "    session_ids = np.array(session_ids)\n",
    "    \n",
    "    distances = []\n",
    "    labels = [] # 1 - если из одного замера, 0 - если из разных\n",
    "\n",
    "    # Теперь создаем все возможные пары и вычисляем расстояния\n",
    "    indices = list(range(len(dataset)))\n",
    "    for i, j in itertools.combinations(indices, 2):\n",
    "        # Вычисляем евклидово расстояние\n",
    "        dist = np.linalg.norm(embeddings[i] - embeddings[j])\n",
    "        distances.append(dist)\n",
    "        \n",
    "        # Определяем, из одного ли замера эта пара\n",
    "        is_same_session = 1 if session_ids[i] == session_ids[j] else 0\n",
    "        labels.append(is_same_session)\n",
    "\n",
    "    distances = np.array(distances)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Используем ROC-кривую для поиска порога\n",
    "    fpr, tpr, thresholds = roc_curve(labels, -distances) # Используем -distance, т.к. roc_curve ожидает \"оценки\", а не расстояния\n",
    "\n",
    "    # Находим порог, который дает точку на ROC-кривой, ближайшую к идеальной (0, 1)\n",
    "    # (минимальная ошибка)\n",
    "    optimal_idx = np.argmin(np.sqrt(fpr**2 + (1 - tpr)**2))\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    # Так как мы передавали -distances, порог тоже будет отрицательным. Берем его по модулю.\n",
    "    optimal_threshold = -optimal_threshold\n",
    "\n",
    "    print(f\"Найдено {len(distances)} пар для анализа.\")\n",
    "    print(f\"Оптимальный порог расстояния: {optimal_threshold:.4f}\")\n",
    "    \n",
    "    return optimal_threshold\n",
    "\n",
    "# Вычисляем наш порог\n",
    "SESSION_THRESHOLD = find_optimal_threshold(model, val_dataset, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b690df2a",
   "metadata": {},
   "source": [
    "Примечание: Порог, который вы найдете, должен быть близок к значению margin_session, которое вы задавали при обучении. Это хороший индикатор того, что модель обучилась правильно.\n",
    "\n",
    "### Шаг 3: Создание Финальной Функции-Детектора\n",
    "Теперь, когда у нас есть модель и вычисленный порог, мы можем написать простую и понятную функцию для решения нашей задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6185f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(signal_np, model, device):\n",
    "    \"\"\"Вспомогательная функция для получения эмбеддинга одного сигнала.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        signal_tensor = torch.tensor(signal_np, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        embedding, _ = model(signal_tensor)\n",
    "        return embedding.cpu()\n",
    "\n",
    "def are_from_same_session(signal_A, signal_B, model, threshold, device):\n",
    "    \"\"\"\n",
    "    Принимает два сигнала и определяет, принадлежат ли они одному замеру.\n",
    "\n",
    "    Args:\n",
    "        signal_A (np.array): Первый временной ряд.\n",
    "        signal_B (np.array): Второй временной ряд.\n",
    "        model: Обученная модель.\n",
    "        threshold (float): Пороговое значение расстояния.\n",
    "        device: Устройство (cpu/cuda).\n",
    "\n",
    "    Returns:\n",
    "        bool: True, если сигналы из одного замера, иначе False.\n",
    "        float: Вычисленное расстояние.\n",
    "    \"\"\"\n",
    "    # Получаем эмбеддинги для каждого сигнала\n",
    "    emb_A = get_embedding(signal_A, model, device)\n",
    "    emb_B = get_embedding(signal_B, model, device)\n",
    "\n",
    "    # Вычисляем евклидово расстояние\n",
    "    distance = F.pairwise_distance(emb_A, emb_B).item()\n",
    "\n",
    "    # Сравниваем с порогом\n",
    "    is_same = distance < threshold\n",
    "    \n",
    "    return is_same, distance\n",
    "\n",
    "# --- Пример использования ---\n",
    "\n",
    "# Возьмем два сигнала, которые точно из одного замера\n",
    "signal_1_data = val_dataset[0]\n",
    "signal_2_data = val_dataset[1] \n",
    "# Предполагаем, что 0 и 1 из одного замера (проверим)\n",
    "print(f\"Проверка пары 1: ID сессии {signal_1_data['session_id']} и {signal_2_data['session_id']}\")\n",
    "\n",
    "is_same, dist = are_from_same_session(\n",
    "    signal_1_data['signal'], \n",
    "    signal_2_data['signal'], \n",
    "    model, \n",
    "    SESSION_THRESHOLD, \n",
    "    DEVICE\n",
    ")\n",
    "print(f\"Результат: {is_same}. Расстояние: {dist:.4f}\\n\")\n",
    "\n",
    "\n",
    "# Теперь возьмем два сигнала, которые точно из разных замеров\n",
    "signal_3_data = val_dataset[0]\n",
    "signal_4_data = val_dataset[-1] # Последний сигнал, скорее всего, из другой сессии\n",
    "print(f\"Проверка пары 2: ID сессии {signal_3_data['session_id']} и {signal_4_data['session_id']}\")\n",
    "\n",
    "is_same, dist = are_from_same_session(\n",
    "    signal_3_data['signal'], \n",
    "    signal_4_data['signal'], \n",
    "    model, \n",
    "    SESSION_THRESHOLD, \n",
    "    DEVICE\n",
    ")\n",
    "print(f\"Результат: {is_same}. Расстояние: {dist:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e136b8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
